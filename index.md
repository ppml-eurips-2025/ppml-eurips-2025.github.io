---
layout: single
title: "PPML @ EurIPS 2025"
permalink: /
classes: wide
header:
    overlay_image: "assets/images/cop2.JPG"
    overlay_filter: 0.4
    overlay_color: "#000"
    caption: "Copenhagen"

feature_row:
  - image_path: /assets/images/amartya_sq.png
    alt: "Amartya Sanyal"
    excerpt: "**[Amartya Sanyal](https://amartya18x.github.io/)**<br><small>amsa@di.ku.dk</small>"
  - image_path: /assets/images/edwige_sq.jpeg
    alt: "Edwige Cyffers"
    excerpt: "**[Edwige Cyffers](https://perso.ens-lyon.fr/edwige.cyffers/)**<br><small>Edwige.Cyffers@ist.ac.at</small>"
  - image_path: /assets/images/Cummings037RT-min-cropped_0_sq.jpg
    alt: "Rachel Cummings"
    excerpt: "**[Rachel Cummings](https://rachelcummings.com/)**<br><small>rac2239@columbia.edu</small>"
  - image_path: /assets/images/chl__sq.jpg
    alt: "Christoph Lampert"
    excerpt: "**[Christoph Lampert](https://cvml.ista.ac.at/)**<br><small>chl@ist.ac.at</small>"
  - image_path: /assets/images/nikita_poster_sq.jpg
    alt: "Nikita Kalinin"
    excerpt: "**[Nikita Kalinin](https://npkalinin.github.io/)**<br><small>nikita.kalinin@ist.ac.at</small>"
  - image_path: /assets/images/peter_sq.png
    alt: "Peter Kairouz"
    excerpt: "**[Peter Kairouz](https://kairouzp.github.io/)**<br><small>kairouz@google.com</small>"



---


## About {#about}

Welcome to the **Privacy-Preserving Machine Learning Workshop at [EurIPS](eurips.cc) 2025**!

The success of machine learning depends on access to large amounts of training data, which often contains sensitive information. This raises issues of legality, competitiveness, and privacy when data is exposed. Neural networks are known to be vulnerable to privacy attacks, a concern that has recently become more visible with large language models (LLMs), where attacks can be carried out directly through prompting. Differential privacy, the gold standard for privacy-preserving learning, has improved in terms of privacy–utility trade-offs thanks to new trust models and algorithms. However, there are still many open questions on how to bridge the gap between attacks and defenses, from developing auditing methods and more effective attacks to the growing interest in machine unlearning.

**Which models best reflect real-world scenarios? How can methods scale to deep learning and foundation models? How are unlearning, auditing, and privacy-preserving machine learning connected, and how can these lines of work be brought together?**

This workshop will bring together researchers from academia and industry working on differential privacy, machine unlearning, privacy auditing, privacy attacks, and related topics.


## Call for Papers {#cfp}

We invite submissions to the **Privacy-Preserving Machine Learning Workshop at EurIPS 2025**.  
We welcome both novel contributions and in-progress work with diverse viewpoints.  


| Important Dates                  | Date (AoE)           |
|-------------------------------------------------|----------------------|
| Paper submission     | **October 10, 2025** |
| Accept/Reject notification            | **October 31, 2025** |
| Workshop                                  | **December 6–7, 2025** |


### Topics of Interest
- Efficient methods for privacy-preserving machine learning  
- Trust models for privacy, including federated learning and data minimization  
- Privacy at inference and privacy for agents interaction and for large language models (fine-tuning, test-time training)  
- Privacy-preserving data generation  
- Differential privacy theory
- Threat models and privacy attacks  
- Auditing methods and interpretation of privacy guarantees  
- Machine unlearning, certifiable machine unlearning, and new unlearning algorithms  
- Relationship between privacy and other issues related to Trustworthy Machine Learning  

### Submission Guidelines
- **Format:** up to **5 pages**, excluding references  
- **Style:** [NeurIPS 2025 template](https://neurips.cc/Conferences/2025/CallForPapers)  
- **Anonymization:** required (double-blind review)  
- **Submission site:** via **OpenReview** — link will be announced here soon  


The list of accepted papers will be published on the website.

We are looking for reviewers to help ensure a fair and constructive review process.  
Each reviewer will be asked to review at most **3 papers**.  
If you are interested in serving as a reviewer, **please fill out the following [form](https://forms.gle/o7gtHwc73vpmtK2P9)**.

---

## Program {#program}

**Coming soon!**

---

## Organizers {#organizers}


{% include feature_row id="feature_row" %}



## Contact {#contact}
Questions? Email us at **[ppml.eurips@gmail.com](mailto:ppml.eurips@gmail.com)**
